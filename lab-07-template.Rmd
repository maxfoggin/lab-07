---
title: "Lab 07 - Modelling course evaluations"
author: [firefox-official]
output: 
  tufte::tufte_html:
    css: ../lab.css
    tufte_variant: "envisioned"
    highlight: pygments
link-citations: yes

---

### Load packages 

```{r load-packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(patchwork)
```

### Read in data

```{r read-data}
evals<-read.csv("data/evals.csv", row.names=1)
```


### Exercise 1

```{r viz-score}
ggplot(data = evals, mapping = aes(x = score))+
  geom_histogram()

summarise(evals, mean(score))
```

The data is right skewed since the mean is 4.17. Students on average rate courses highly, this is perhaps slightly higher but not unusual.

### Exercise 2

```{r viz-score-bty, eval = TRUE}

plot_geom_point  <- ggplot(data = evals, mapping = aes(x = bty_avg, y = score))+
  geom_point()

plot_geom_jitter <- ggplot(data = evals, mapping = aes(x = bty_avg, y = score))+
  geom_jitter()

plot_geom_point + plot_geom_jitter
```

The first plot is misleading because there's points on top of each other - we can see on the second plot that there's a lot of points clumping and overlapping. 

### Exercise 3

```{r fit-score_bty_fit, eval = TRUE}
# remove eval = FALSE from the code chunk options after filling in the blanks
score_bty_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg, data = evals)
```

```{r tidy-score_bty_fit, eval = TRUE}
# remove eval = FALSE from the code chunk options after filling in the blanks
tidy(score_bty_fit)
```

score = bty_avg*0.06663704 + 3.88033795

### Exercise 4

```{r viz-score_bty_fit}
plot_geom_jitter +
  geom_smooth(method = "lm", se = FALSE, colour = "orange")
```

### Exercise 5

For each additional point the  is bty_avg is higher, the score is expected to be higher, on average,  by 0.06663704. 

### Exercise 6

For a bty_score of 0, the score is expected , on average, to be 3.88033795.

### Exercise 7

```{r glance-score_bty_fit, eval = FALSE}
# remove eval = FALSE from the code chunk options after filling in the blanks
glance(score_bty_fit)
```

3.5 percent of the variability in score can be explained by the regression model. this model is not very useful for interpreting our response variable as the r squared value is too low. 

### Exercise 8

```{r viz-score_bty_fit-diagnostic, eval = FALSE}
# remove eval = FALSE from the code chunk options after filling in the blanks
score_bty_aug <- augment(score_bty_fit$fit)

ggplot(___)
```

*Add your narrative here.*

### Exercise 9

```{r fit-score_rank_fit}
# fit model

# tidy model output
```

*Add your narrative here.*

### Exercise 10

```{r fit-score_gender_fit}
# fit model

# tidy model output
```

```{r score_gender_intercept, echo = FALSE, eval = FALSE}
# remove eval = FALSE from the code chunk options
score_gender_intercept <- tidy(score_gender_fit) %>% 
  filter(term == "(Intercept)") %>%
  select(estimate) %>%
  pull()
```

```{r score_gender_slope, echo = FALSE, eval = FALSE}
# remove eval = FALSE from the code chunk options after filling in the blanks
score_gender_slope <- tidy(score_gender_fit) %>% 
  filter(term == "___") %>%
  select(___) %>%
  pull()
```

*Add your narrative here.*

### Exercise 11

```{r fit-score_bty_gender_fit}
# fit model

# tidy model output
```

*Add your narrative here.*

### Exercise 12

```{r glance-score_bty_gender_fit}
# glance model output
```

*Add your narrative here.*

### Exercise 13

*Add your linear model here. Don't worry about math notation, you can use things like score-hat.*

### Exercise 14

*Add your narrative here. One sentence is sufficient.*

### Exercise 15

*Add your narrative here. One sentence is sufficient.*

### Exercise 16

*Add your narrative here. One sentence is sufficient.*

### Exercise 17

*Add your narrative here. One sentence is sufficient.*

### Exercise 18

```{r fit-score_bty_gender_rank_fit}
# fit model

# glance model output
```

*Add your narrative here. One sentence is sufficient.*
